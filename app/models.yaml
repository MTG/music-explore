datasets:
  msd:
    name: MSD
    description: 'Trained on Million Song Dataset, 200k tracks annotated by tags from Last.fm'
    tags: [rock, pop, alternative, indie, electronic, female vocalists, dance, 00s, alternative rock, jazz, beautiful,
           metal, chillout, male vocalists, classic rock, soul, indie rock, mellow, electronica, 80s, folk, 90s, chill,
           instrumental, punk, oldies, blues, hard rock, ambient, acoustic, experimental, female vocalist, guitar,
           hip-hop, 70s, party, country, easy listening, sexy, catchy, funk, electro, heavy metal, progressive rock,
           60s, rnb, indie pop, sad, house, happy]
  mtt:
    name: MTAT
    description: 'Trained on MagnaTagaTune, 25k tracks with tags by human annotators'
    tags: [guitar, classical, slow, techno, strings, drums, electronic, rock, fast, piano, ambient, beat, violin, vocal,
           synth, female, indian, opera, male, singing, vocals, no vocals, harpsichord, loud, quiet, flute, woman,
           male vocal, no vocal, pop, soft, sitar, solo, man, classic, choir, voice, new age, dance, male voice,
           female vocal, beats, harp, cello, no voice, weird, country, metal, female voice, choral]
  audioset:
    name: AudioSet
    description: 'Trained on AudioSet, 1.8 million audio clips from Youtube annotated with the AudioSet taxonomy'
    tags: []

architectures:
  musicnn:
    name: MusiCNN
    essentia-algorithm: TensorflowPredictMusiCNN
    description: 'Musically-motivated convolutional neural network (6 layers, 790k parameters)'
    datasets: [msd, mtt]
    layers:
      taggrams:
        name: 'model/Sigmoid'
        size: 50
      embeddings:
        name: 'model/dense/BiasAdd'
        size: 200
    segment-length: 3000
  vgg:
    name: VGG
    description: 'Baseline architecture from computer vision, adapted to audio (5 layers, 605k parameters)'
    datasets: [msd, mtt]
    essentia-algorithm: TensorflowPredictMusiCNN
    layers:
      taggrams:
        name: 'model/Sigmoid'
        size: 50
      embeddings:
        name: 'model/flatten/Reshape'
        size: 256
    segment-length: 3000
  vggish:
    name: VGGish
    description: 'Baseline architecture from computer vision, original implementation (5 layers, 62m parameters)'
    datasets: [audioset]
    essentia-algorithm: TensorflowPredictVGGish
    layers:
      embeddings:
        name: 'model/vggish/fc2/BiasAdd'
        size: 128
    segment-length: 960

algorithms:
  TensorflowPredictMusiCNN:
    melspec-algorithm: TensorflowInputMusiCNN
    frame-size: 512
    hop-size: 256
    patch-size: 187
    number-bands: 96
  TensorflowPredictVGGish:
    melspec-algorithm: TensorflowInputVGGish
    frame-size: 400
    hop-size: 160
    patch-size: 96
    number-bands: 64

layers:
  taggrams:
    name: Taggrams
    description: 'Show tag activations from the output layer of neural network'
  embeddings:
    name: Embeddings
    description: 'Show embeddings from the second-to-last layer of neural network'

offline-projections: [pca, std-pca]

projections:
  original:
    name: Original
    description: 'Select 2 tags or embedding layers to visualize on X and Y axis'
  pca:
    name: PCA
    description: 'Use Principal Component Analysis'
  std-pca:
    name: STD-PCA
    description: 'Use PCA, with prior standardization along dimensions'
  tsne:
    name: t-SNE
    description: 'Use 2D t-SNE. Best used with N < 50, becomes slow for higher numbers'
  umap:
    description: 'Use UMAP. Best used with N < 50, becomes slow for higher numbers'
    name: UMAP
